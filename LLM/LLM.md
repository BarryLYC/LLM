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

大语言的概念

GPT（生成式预训练转换器）和BERT（双向编码器表示器）

* * *

## 1\. LLM 的涌现能力

## **数据驱动的突破**

- 当数据量超过某个临界点时，模型性能会显著提升，并展现出小模型中不存在的能力。
- **现象**：AI 学者难以完全解释这种变化。

### **大语言模型的涌现能力**

1.  **上下文学习（In-context Learning）**：
    - GPT-3 首次引入了这种能力。
    - **定义**：模型通过自然语言指令和任务描述，在不进行额外训练或梯度更新的情况下，根据输入文本完成推理任务。==怎么利用==？达到用户期望
2.  **指令遵循（Instruction Following）**：
    - 通过指令调优（Instruction Tuning），模型可以在没有显式样本的情况下，根据任务指令执行新任务，显著提高泛化能力。
3.  **循序渐进的推理（Step-by-step Reasoning）**：
    - 小模型难以解决的多步骤推理任务（如数学题），通过 CoT（Chain-of-Thought）思维链技术，模型可分步生成中间推理结果，最终得出答案。==怎没用好，怎么写prompt或技术手段，将这几个能力用好==？==开发人员==？

* * *

## 2\. LLM 的训练方式

### **训练目标**

- **目标**：通过大规模文本数据训练模型，让其学习语言的结构、语法和语义。

### **自我监督学习（==具体怎样，输入输出，<span style="color: #e03e2d;">核心技术原理</span>，样本是什么的方法，为什么这样准备数据，损失函数怎么设计，损失项==）**

- **定义**：模型通过预测序列中的下一个词或标记，自生成训练标签。
- **优点**：无需人工标注，自动生成监督信号。

### **两阶段训练流程**

1.  **预训练（Pre-training）**：
    - 数据：巨大的、多样化的数据集（如网站、书籍、文章）。==训练的方法==。
    - **目标**：学习通用的语言模式和表征。
2.  **微调（Fine-tuning）**：
    - 数据：针对任务或领域的更小数据集。
    - **目标**：使模型适应特定任务的需求。

* * *

# LLaMA 模型特点

### **开源模型汇总**

**![b9fbb19a95fc32bd692118a0bd271b07.png](../_resources/b9fbb19a95fc32bd692118a0bd271b07.png)**

B（Billion）表示 **十亿**（109）。T（Trillion）表示 **万亿**（1012）。

==词表大小==

### **模型架构**

- 基于 **Causal Decoder-only Transformer**。
- 设计上优于传统 Transformer，针对稳定性和性能进行了优化：

1.  **Layer Normalization**：
    - **传统方式**：Post Layer Norm（容易导致梯度消失）。
    - **改进**：使用 Pre Layer Norm 提升训练稳定性，去掉偏置项并引入 RMS Norm（均方根归一化）。
2.  **激活函数**：
    - 使用 SwiGLU 替代 ReLU 激活函数。
    - **SwiGLU 机制**：
        - FFN 增加一个权重矩阵（共 3 个），中间维度从 4d 调整为 23d\\frac{2}{3}d，保持参数量一致，同时提升效率。
3.  **位置编码**：
    - 去除绝对位置编码，采用 RoPE（旋转位置编码）。
    - **优势**：更好地捕捉相对位置关系，适应动态场景。![c46797aa6395daffd3aca3c1f28c1d00.png](../_resources/c46797aa6395daffd3aca3c1f28c1d00.png)

* * *

&nbsp;

==第一阶段：不要那么细节，最核心的概念和原理搞清楚，和其他方法有什么差异==

==第二阶段：细节，核心技术。动手。==