# Embedding

在 Transformer 模型中，**embedding（嵌入）** 是将离散的输入数据（如单词、字符或其他符号）转换成模型可以理解的连续数值表示（向量）的过程和结果。

- **输入**：通常是离散的标记（token），如单词、子词或字符。
- **输出**：每个标记都会被映射成一个固定维度的向量表示（例如 512 维）。
- **意义**：embedding 向量编码了输入的语义或特征信息，便于模型捕捉它们之间的关系。

### **Transformer 中的 Embedding 具体用法**

应用在以下2个地方：

#### **(1) 输入嵌入层（Input Embedding）**

将输入的离散标记（通常是整数 ID）映射到连续的向量空间。

- **过程**：
    - 输入：一个表示单词序列的整数序列，例如 `[12, 45, 78]`。
    - 操作：通过查表（Embedding Lookup）将每个整数映射到一个向量，例如：
        - `12 → [0.1, 0.3, -0.5, ...]`
        - `45 → [-0.2, 0.6, 0.8, ...]`
    - 输出：一个==矩阵==，每一行是一个标记的嵌入向量。

#### **(2) 位置嵌入层（Positional Embedding）**

Transformer 模型中没有循环结构（如 RNN），无法通过顺序处理理解输入标记的位置关系，因此需要显式地编码位置信息。

- **方法**：
    - 添加一个固定的或可学习的向量表示来表示每个标记的位置。
    - 输出是输入嵌入与位置嵌入的逐元素相加结果。

**示例**： 如果第一个单词的输入嵌入是 `[0.1, 0.3, -0.5]`，位置嵌入是 `[0.2, -0.1, 0.4]`，那么最终的输入向量是 `[0.3, 0.2, -0.1]`。

&nbsp;

# **Benchmark**

**Benchmark** 是指用于评估和比较算法或模型性能的==基准测试框架或数据集==。

#### **特点和作用**

- **性能评估**：Benchmark 提供一个标准化的数据集和评估指标，用于测试模型在特定任务上的表现。
- **公平比较**：通过在相同的条件下测试不同模型或算法，确保对比结果的公平性。
- **推动研究进展**：研究人员通常会以 benchmark 上的性能提升作为进步的标志。

#### **例子**

- **计算机视觉**：
    - **ImageNet**：常用作图像分类任务的 benchmark 数据集。
    - **COCO**：用于目标检测、语义分割等任务。
- **自然语言处理**：
    - **GLUE**、**SuperGLUE**：用于评估 NLP 模型在句子理解任务上的性能。
    - **SQuAD**：用于问答系统的评估。

#### **在机器学习流程中的位置**

Benchmark 是一个 **评估工具**，研究者会使用 benchmark 数据集和指标来测试模型的效果，以验证模型是否达到预期性能。

# **Backbone**

**Backbone** 是指模型的==核心框架或主干网络==，通常作为==特征提取的基础结构==。

#### **特点和作用**

- **特征提取**：Backbone 负责从原始输入（如图像、文本）中==提取高质量的特征==，用于后续的任务（分类、检测等）。
- **可迁移性**：==许多 backbone 是预训练的模型==，可以迁移到其他任务中以节省训练时间。
- **模块化**：Backbone 是模型的一部分，可以==与其他组件（如检测头、分类器等）结合==，形成完整的任务解决方案。

#### **例子**

- **计算机视觉领域**：
    - **ResNet**（Residual Network）：经典的 backbone，用于提取图像特征。
    - **VGG**：简单但强大的卷积网络结构。
    - **EfficientNet**：计算效率与性能平衡的模型。
    - **ViT**（Vision Transformer）：基于 Transformer 的图像处理 backbone。
- **自然语言处理领域**：
    - **BERT**（Bidirectional Encoder Representations from Transformers）：广泛用于 NLP 任务的 backbone。
    - **GPT**（Generative Pre-trained Transformer）：用于文本生成和理解。
    - **RoBERTa、DeBERTa**：BERT 的优化版本。

#### **在模型中的位置**

Backbone 是模型的 **核心模块**，它定义了如何从数据中提取信息，是许多复杂模型（如目标检测模型 Mask R-CNN）的基础。

&nbsp;

# **1\. Zero-Shot 推理性能**

**定义**  
Zero-Shot 推理是指模型**在没有见过任何特定任务训练样本的情况下**，直接利用预训练的知识来解决任务的能力。

#### **特点**

- **无任务微调**：模型直接基于其预训练知识完成任务，无需针对目标任务的特定训练数据。
- **依赖强大的预训练**：预训练模型（如 GPT 系列或 T5）通过大量数据学习了广泛的语言知识和推理能力。
- **需要明确的提示设计（Prompt Engineering）**：通过设计合适的提示（Prompt），将任务描述清楚，以便模型理解任务。

&nbsp;

# **2\. Few-Shot 推理性能**

**定义**  
Few-Shot 推理是指模型在**仅有极少量标注样本**的情况下（通常 1-5 个），通过上下文学习完成任务的能力。

#### **特点**

- **上下文学习（In-Context Learning）**：模型通过少量示例学习任务模式，而无需显式地更新权重。
- **提示包含示例（Few-Shot Prompting）**：提示中包含了少量标注样本，让模型理解任务格式和逻辑。
- **更高的性能**：相比 Zero-Shot，Few-Shot 推理可以通过提供示例来显著提高模型性能。

&nbsp;

# **衡量指标**

Few-Shot 性能与 Zero-Shot 性能类似，通常通过：

- 准确率
- F1 分数
- 平均绝对误差（对于回归任务）